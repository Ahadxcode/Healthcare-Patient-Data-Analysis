# -*- coding: utf-8 -*-
"""HealthcarePatientSystem

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SkdUH9aSinDxKvQvK6-0v0qqJTBZ7JJH
"""



!pip install pandas numpy faker matplotlib seaborn pyspark

import pandas as pd
import numpy as np
from faker import Faker
import random

fake = Faker()

# Config
n_patients = 10000
n_records = 50000
diagnosis_codes = ['A01', 'B02', 'C03', 'D04', 'E05']

# Generate patients
patients = pd.DataFrame({
    "patient_id": range(1, n_patients+1),
    "name": [fake.name() for _ in range(n_patients)],
    "dob": [fake.date_of_birth(minimum_age=0, maximum_age=90) for _ in range(n_patients)],
    "gender": [random.choice(['M','F']) for _ in range(n_patients)]
})

# Generate admissions
admissions = []
for _ in range(n_records):
    pid = random.randint(1, n_patients)
    admit_date = fake.date_between(start_date='-2y', end_date='today')
    discharge_date = admit_date + pd.Timedelta(days=random.randint(1,15))
    admissions.append([pid, admit_date, discharge_date,
                       random.choice(diagnosis_codes), random.randint(1,5)])

admissions = pd.DataFrame(admissions,
                          columns=["patient_id","admission_date","discharge_date","diagnosis_code","hospital_id"])

# Save CSVs
patients.to_csv("patients.csv", index=False)
admissions.to_csv("admissions.csv", index=False)

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date, count, avg

spark = SparkSession.builder.appName("HealthcareAnalysis").getOrCreate()

admissions = spark.read.csv("admissions.csv", header=True, inferSchema=True)
patients   = spark.read.csv("patients.csv", header=True, inferSchema=True)

# Convert dates
admissions = admissions.withColumn("admission_date", to_date(col("admission_date"))) \
                       .withColumn("discharge_date", to_date(col("discharge_date")))

# Top 5 diagnoses
top_diag = (admissions.groupBy("diagnosis_code")
                       .agg(count("*").alias("cases"))
                       .orderBy(col("cases").desc())
                       .limit(5))
top_diag.show()

# Average stay
avg_stay = (admissions.withColumn("stay_length", col("discharge_date").cast("long") - col("admission_date").cast("long"))
                       .groupBy("hospital_id")
                       .agg(avg("stay_length").alias("avg_stay")))
avg_stay.show()

# Step 5: Visualization (Fixed Version)

from pyspark.sql.functions import col
import seaborn as sns
import matplotlib.pyplot as plt

# ✅ Get Top 5 Diagnoses using PySpark
diag_counts = (
    admissions.groupBy("diagnosis_code")
              .count()
              .orderBy(col("count").desc())
              .limit(5)
)

# ✅ Convert PySpark DataFrame to Pandas for plotting
diag_counts_pd = diag_counts.toPandas()

# ✅ Seaborn Plot
sns.barplot(x="diagnosis_code", y="count", data=diag_counts_pd)
plt.title("Top 5 Diagnoses")
plt.xlabel("Diagnosis Code")
plt.ylabel("Number of Cases")